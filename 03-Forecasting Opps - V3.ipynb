{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3502dbb2-a4ef-4499-bb28-3005adc353be",
   "metadata": {},
   "source": [
    "### -Open with Salesforce Environment-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0934ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime, timezone, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import OrderedDict\n",
    "from simple_salesforce import Salesforce, SalesforceLogin, SFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "879a4cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<simple_salesforce.api.Salesforce object at 0x000001C63B5F5C40>\n"
     ]
    }
   ],
   "source": [
    "username = 'adriel.piacquadio@engbim.com'\n",
    "password = 'Adriel2021'\n",
    "security_token = 'UiFCCsvyGhC115hMDBpeeC6K'\n",
    "\n",
    "sf = Salesforce(username=username, password=password, security_token=security_token)\n",
    "print(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f017f488-31f5-4053-bd34-c7b1481ec895",
   "metadata": {},
   "source": [
    "### Query for Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bff2d23-99d5-4e70-b2dd-385b0baffb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_salesforce_opps(sf, date):\n",
    "    # Realizar la consulta SOQL con la fecha proporcionada\n",
    "    query = f\"SELECT Project__c, Id, Name, CreatedDate, Proposal_Delivery_Date__c, Internal_Owner__c, Amount, Deal_Type__c, CloseDate, Estimator__c, IsWon, Division__c, Trades__c, Project_stage__c, End_Market__c, Point_of_Contact_within_Account__c, Customer_Classification__c, StageName FROM Opportunity WHERE Project_stage__c != 'Operations' AND  CreatedDate > {date}\"\n",
    "    response = sf.query(query)\n",
    "    \n",
    "    # Extraer registros y crear DataFrame\n",
    "    records = response['records']\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Eliminar la columna 'attributes'\n",
    "    df.drop(columns=['attributes'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34c6486-5f5a-4e95-a4e3-ae5a9280bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_salesforce_opps2(sf, date1, date2):\n",
    "    # Realizar la consulta SOQL con la fecha proporcionada\n",
    "    query = f\"SELECT Project__c, Id, Name, CreatedDate, Proposal_Delivery_Date__c, Internal_Owner__c, Amount, Deal_Type__c, CloseDate, Estimator__c, IsWon, Division__c, Trades__c, Project_stage__c, End_Market__c, Point_of_Contact_within_Account__c, Customer_Classification__c, StageName FROM Opportunity WHERE Project_stage__c != 'Operations' AND  CreatedDate > {date1} AND  CreatedDate < {date2}\"\n",
    "    response = sf.query(query)\n",
    "    \n",
    "    # Extraer registros y crear DataFrame\n",
    "    records = response['records']\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Eliminar la columna 'attributes'\n",
    "    df.drop(columns=['attributes'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_opps_00 = query_salesforce_opps2(sf, '2021-09-08T00:41:46.000+0000', '2022-01-17T12:47:33.000+0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea368a11-5788-46c5-b23d-5752d1ee9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha inicial para la consulta\n",
    "date_opps = '2021-01-01T00:00:00.000+0000'\n",
    "all_df_opps = []\n",
    "\n",
    "while True:\n",
    "    # Obtener los datos desde Salesforce\n",
    "    df_opps = query_salesforce_opps(sf, date_opps)\n",
    "    \n",
    "    # Si no hay más datos, salir del bucle\n",
    "    if df_opps.empty:\n",
    "        break\n",
    "    \n",
    "    # Agregar el DataFrame actual a la lista de todos los DataFrames\n",
    "    all_df_opps.append(df_opps)\n",
    "    \n",
    "    # Actualizar la fecha para la siguiente consulta\n",
    "    date_opps = df_opps['CreatedDate'].max()\n",
    "    \n",
    "    # Verificar si se ha alcanzado el límite de 2000 registros\n",
    "    if len(df_opps) < 2000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56cc32f4-4c1f-49c2-bf1e-9e7515715d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los DataFrames en uno solo\n",
    "df_opps_combined = pd.concat(all_df_opps, ignore_index=True)\n",
    "\n",
    "# Combinar df_opps_00 con df_opps_combined\n",
    "df_opps_final = pd.concat([df_opps_00, df_opps_combined], ignore_index=True)\n",
    "df_opps_final = df_opps_final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbd4b43-9634-4f62-a0e8-46875a2ef89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_opps.to_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\Opportunities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483fed89-5e8d-44f9-85c5-8289c4233b2d",
   "metadata": {},
   "source": [
    "### Query for Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b8b2fe7-a573-4050-a3d1-1b44e3c47fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_salesforce_proj(sf, id):\n",
    "    # Realizar la consulta SOQL con la fecha proporcionada\n",
    "    query = f\"SELECT Id, Name, Project_State__c FROM Project__c WHERE Id >= '{id}'\"\n",
    "    response = sf.query(query)\n",
    "    \n",
    "    # Extraer registros y crear DataFrame\n",
    "    records = response['records']\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Eliminar la columna 'attributes'\n",
    "    df.drop(columns=['attributes'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e148e255-2395-4aaf-b6fa-d97f594b7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id inicial para la consulta\n",
    "id_proj = 'a0p7V000007JxehQAC'\n",
    "all_df_proj = []\n",
    "\n",
    "while True:\n",
    "    # Obtener los datos desde Salesforce\n",
    "    df_proj = query_salesforce_proj(sf, id_proj)\n",
    "    \n",
    "    # Si no hay más datos, salir del bucle\n",
    "    if df_proj.empty:\n",
    "        break\n",
    "    \n",
    "    # Agregar el DataFrame actual a la lista de todos los DataFrames\n",
    "    all_df_proj.append(df_proj)\n",
    "    \n",
    "    # Actualizar el Id para la siguiente consulta\n",
    "    id_proj = df_proj['Id'].max()\n",
    "    \n",
    "    # Verificar si se ha alcanzado el límite de 2000 registros\n",
    "    if len(df_proj) < 2000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d028806-5ae6-4e74-9061-efc49102b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj_final = pd.concat(all_df_proj, ignore_index=True)\n",
    "df_proj_final = df_proj_final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c120e922-10f9-42f8-a10a-cebb3e22fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_proj.to_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\Projects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40310c4-f580-4039-96a7-500056f95d47",
   "metadata": {},
   "source": [
    "### Query for Clients & Contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70318de-2bc1-43c9-b7e8-981bbae13569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_salesforce_acc(sf, id):\n",
    "    # Realizar la consulta SOQL con la fecha proporcionada\n",
    "    query = f\"SELECT AccountId, Title, Name, Id, Account.Industry, Account.Name, Account.Sales_Division__c, Account.Type, Account.Type__c, Account.BillingAddress FROM Contact WHERE Id >= '{id}' ORDER BY Id ASC\"\n",
    "    response = sf.query(query)\n",
    "    \n",
    "    # Extraer registros y crear DataFrame\n",
    "    records = response['records']\n",
    "    df = pd.DataFrame(records)\n",
    "    \n",
    "    # Eliminar la columna 'attributes'\n",
    "    df.drop(columns=['attributes'], inplace=True)\n",
    "\n",
    "    # Extraer datos anidados en la columna 'Account' y convertirlos en columnas separadas\n",
    "    account_data = df['Account'].apply(lambda x: pd.Series(x, dtype='object'))  # Esto convierte diccionarios en columnas\n",
    "    account_data.columns = ['Account.' + col for col in account_data.columns]  # Prefijar con 'Account.'\n",
    "    if 'Account.attributes' in account_data.columns:\n",
    "        account_data.drop(columns=['Account.attributes'], inplace=True)\n",
    "    \n",
    "    # Concatenar los datos de Account al DataFrame principal\n",
    "    df = pd.concat([df.drop(columns=['Account']), account_data], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece8b55e-b4eb-4a91-9e8c-e4058c90d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id inicial para la consulta\n",
    "id_acc = '0030e00002GntyVAAR'\n",
    "all_df_acc = []\n",
    "\n",
    "while True:\n",
    "    # Obtener los datos desde Salesforce\n",
    "    df_acc = query_salesforce_acc(sf, id_acc)\n",
    "    \n",
    "    # Si no hay más datos, salir del bucle\n",
    "    if df_acc.empty:\n",
    "        break\n",
    "    \n",
    "    # Agregar el DataFrame actual a la lista de todos los DataFrames\n",
    "    all_df_acc.append(df_acc)\n",
    "    \n",
    "    # Actualizar el Id para la siguiente consulta\n",
    "    id_acc = df_acc['Id'].max()\n",
    "    \n",
    "    # Verificar si se ha alcanzado el límite de 2000 registros\n",
    "    if len(df_acc) < 2000:\n",
    "        break\n",
    "\n",
    "df_acc_combined = pd.concat(all_df_acc, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4312238-9fd7-4619-9e6a-ee12b5704be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get not accesible IDs\n",
    "\n",
    "query_acc_00 = f\"SELECT AccountId, Title, Name, Id, Account.Industry, Account.Name, Account.Sales_Division__c, Account.Type, Account.Type__c, Account.BillingAddress FROM Contact WHERE Id >= '0030P00001t16W8QAI' AND Id <= '0030P00002HHH52QAH' ORDER BY Id ASC\"\n",
    "response_acc_00 = sf.query(query_acc_00)\n",
    "\n",
    "# Extraer registros y crear DataFrame\n",
    "records_acc_00 = response_acc_00['records']\n",
    "df_acc_00 = pd.DataFrame(records_acc_00)\n",
    "\n",
    "# Eliminar la columna 'attributes'\n",
    "df_acc_00.drop(columns=['attributes'], inplace=True)\n",
    "\n",
    "# Extraer datos anidados en la columna 'Account' y convertirlos en columnas separadas\n",
    "account_data_00 = df_acc_00['Account'].apply(lambda x: pd.Series(x, dtype='object'))  # Esto convierte diccionarios en columnas\n",
    "account_data_00.columns = ['Account.' + col for col in account_data_00.columns]  # Prefijar con 'Account.'\n",
    "account_data_00.drop(columns=['Account.attributes'], inplace=True)\n",
    "\n",
    "# Concatenar los datos de Account al DataFrame principal\n",
    "df_acc_00 = pd.concat([df_acc_00.drop(columns=['Account']), account_data_00], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "108eb3fc-3dc1-44f1-98e6-db9d25393163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar df_acc_00 con df_acc_combined\n",
    "df_acc_final = pd.concat([df_acc_00, df_acc_combined], ignore_index=True)\n",
    "\n",
    "# Función para obtener el valor de 'state' de un OrderedDict\n",
    "def get_state_value(x):\n",
    "    if isinstance(x, OrderedDict):\n",
    "        return x.get('state', None)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Aplicar la función a la columna 'Account.BillingAddress'\n",
    "df_acc_final['Account.BillingAddress'] = df_acc_final['Account.BillingAddress'].apply(get_state_value)\n",
    "\n",
    "df_acc_final = df_acc_final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b27dbc70-3a4a-4ca8-ac78-8c17315e2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_acc.to_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\ContactsAccounts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4240ab",
   "metadata": {},
   "source": [
    "### Joining SOQL Objects: Project - Opp. - Account - Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e673b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_opps = pd.read_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\Opportunities.csv')\n",
    "#df_acc = pd.read_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\ContactsAccounts.csv')\n",
    "#df_proj = pd.read_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\Projects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d5ca772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opps_final = df_opps_final.rename(columns = {'Project__c':'ProjectId', 'Id':'OppId', 'Name':'Opportunity', 'Proposal_Delivery_Date__c':'DeliveryDate',\n",
    "                                    'Internal_Owner__c':'InternalOwner', 'Sales_Division__c':'SalesDivision', \n",
    "                                    'Deal_Type__c':'DealType', 'Estimator__c':'Estimator', 'Division__c':'Division',\n",
    "                                    'Trades__c':'Trades', 'Project_stage__c':'ProjectStage', 'End_Market__c':'EndMarket',\n",
    "                                    'Point_of_Contact_within_Account__c':'ContactId', 'Customer_Classification__c':'CustomerClass'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a69a8b20-820d-4df3-99b2-b1b8e0caf2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ProjectId', 'OppId', 'Opportunity', 'CreatedDate', 'DeliveryDate',\n",
      "       'InternalOwner', 'Amount', 'DealType', 'CloseDate', 'Estimator',\n",
      "       'IsWon', 'Division', 'Trades', 'ProjectStage', 'EndMarket', 'ContactId',\n",
      "       'CustomerClass', 'StageName'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_opps_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c030f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opps_final = df_opps_final[['ProjectId', 'OppId','Opportunity', 'Division', 'DealType', 'CreatedDate',\n",
    "                               'DeliveryDate', 'CloseDate', 'InternalOwner', 'Estimator', 'Trades',\n",
    "                               'EndMarket', 'ProjectStage', 'StageName','IsWon', 'Amount',\n",
    "                               'CustomerClass', 'ContactId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20aab715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj_final = df_proj_final.rename(columns = {'Id':'ProjectId', 'Name':'Project', 'Project_State__c':'ProjectState'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e028d1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_final = df_acc_final.rename(columns = {'Account.Industry':'AccountIndustry', 'Account.Name':'AccountName',\n",
    "                                              'Account.Sales_Division__c':'SalesDivision', 'Account.Type':'AccountType',\n",
    "                                              'Account.Type__c':'CompanyType', 'Id':'ContactId',\n",
    "                                              'Account.BillingAddress':'BillingAddress'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a68c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_final = df_acc_final[['AccountId', 'AccountName', 'BillingAddress','AccountType',\n",
    "                             'AccountIndustry', 'CompanyType', 'SalesDivision', \n",
    "                             'Name', 'Title', 'ContactId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a99a570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opps_proj = pd.merge(df_opps_final, df_proj_final, on='ProjectId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "091090dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opps_proj.fillna({'Project': df_opps_proj['Opportunity']}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3021b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_opps_proj, df_acc_final, on='ContactId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "712f2059-9f9a-453e-a072-3015f18627f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ProjectId', 'OppId', 'Opportunity', 'Division', 'DealType',\n",
      "       'CreatedDate', 'DeliveryDate', 'CloseDate', 'InternalOwner',\n",
      "       'Estimator', 'Trades', 'EndMarket', 'ProjectStage', 'StageName',\n",
      "       'IsWon', 'Amount', 'CustomerClass', 'ContactId', 'Project',\n",
      "       'ProjectState', 'AccountId', 'AccountName', 'BillingAddress',\n",
      "       'AccountType', 'AccountIndustry', 'CompanyType', 'SalesDivision',\n",
      "       'Name', 'Title'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f96144d6-8c20-4adb-943e-6597d16f8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ProjectId', 'Project', 'OppId', 'Opportunity', 'ProjectState', 'Division', 'DealType',\n",
    "         'CreatedDate', 'DeliveryDate', 'CloseDate', 'InternalOwner', 'Estimator',\n",
    "         'Trades', 'EndMarket', 'ProjectStage', 'StageName','IsWon', 'Amount', 'ContactId',\n",
    "         'AccountId', 'AccountName', 'BillingAddress','AccountType', 'CustomerClass',\n",
    "         'AccountIndustry', 'CompanyType', 'SalesDivision',\n",
    "         'Name', 'Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c352765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842a952",
   "metadata": {},
   "source": [
    "### Predicting Conversion Chances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fde5e356-a104-469a-90dc-a9d429e6e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import uniform, randint\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf303034-47ba-4e18-868a-51055d63a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdrielPiacquadioENG\\AppData\\Local\\Temp\\ipykernel_27208\\947589054.py:3: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask_regex_1 = df['Opportunity'].str.contains(regex_opp_1, na=False)\n"
     ]
    }
   ],
   "source": [
    "regex_opp_1 = r'CO(-|([0-9]{1,2}))'\n",
    "mask_1 = df['DealType'].isna() | (df['DealType'] == '')\n",
    "mask_regex_1 = df['Opportunity'].str.contains(regex_opp_1, na=False)\n",
    "df.loc[mask_1 & mask_regex_1, 'DealType'] = 'Closed Budget – Change Order'\n",
    "\n",
    "regex_opp_2 = r'T&M'\n",
    "mask_regex_2 = df['Opportunity'].str.contains(regex_opp_2, na=False)\n",
    "df.loc[mask_1 & mask_regex_2, 'DealType'] = 'T&M New Contract (with NTE)'\n",
    "\n",
    "df['DealType'] = df['DealType'].fillna('Closed Budget – New Contract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78811a42-938c-46ca-8854-669fcfaf6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CreatedDate'] = pd.to_datetime(df['CreatedDate'])\n",
    "df['CreatedDate2'] = df['CreatedDate'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2630887-da1b-419e-9c8c-3578724a443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['ContactId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc234f7d-f1ed-43e7-bf0d-1b0cbabb2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ProjectState'] = np.where(df['ProjectState'].isnull(), df['BillingAddress'], df['ProjectState'])\n",
    "df['ProjectState'] = df['ProjectState'].fillna('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c26e4575-3ea5-4886-9130-8c554d5e418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['InternalOwner', 'SalesDivision', 'Estimator', 'Trades', 'ProjectStage', 'IsWon', 'ContactId', 'Name', 'AccountId', 'AccountName', 'AccountType', 'CustomerClass', 'ProjectState']\n",
    "\n",
    "# Verificar si alguna de las columnas tiene valores nulos\n",
    "columnas_con_nulos = df[columns].isnull().any()\n",
    "\n",
    "# Filtrar el DataFrame para eliminar las filas con valores nulos en esas columnas\n",
    "if not columnas_con_nulos.empty:\n",
    "    df = df.dropna(subset=columnas_con_nulos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5bdc506-e7ae-4896-83e5-284d8e74d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'Division'\n",
    "unique_divisions = df['Division'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "division_to_id = {division: i+1 for i, division in enumerate(unique_divisions)}\n",
    "\n",
    "# Crear la nueva columna 'DivisionId' utilizando el diccionario de mapeo\n",
    "df['DivisionId'] = df['Division'].map(division_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "891f87b6-b97d-4852-9901-baf314f31f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'DealType'\n",
    "unique_deals = df['DealType'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "deal_to_id = {deal: i+1 for i, deal in enumerate(unique_deals)}\n",
    "\n",
    "# Crear la nueva columna 'InternalOwnerId' utilizando el diccionario de mapeo\n",
    "df['DealTypeId'] = df['DealType'].map(deal_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6f72cc9-a2b1-4071-9df3-1cda86a7cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'InternalOwner'\n",
    "unique_owners = df['InternalOwner'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "owner_to_id = {owner: i+1 for i, owner in enumerate(unique_owners)}\n",
    "\n",
    "# Crear la nueva columna 'InternalOwnerId' utilizando el diccionario de mapeo\n",
    "df['InternalOwnerId'] = df['InternalOwner'].map(owner_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5798eef-fd4e-46a5-a899-cccedf6720db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SalesDivisionId'] = np.where(df['SalesDivision'] == 'Inbound', 1, \n",
    "                                 np.where(df['SalesDivision'] == 'Outbound', 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8eff1c29-7110-4149-a0d9-53906f70a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'Estimator'\n",
    "unique_estimators = df['Estimator'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "estimator_to_id = {estimator: i+1 for i, estimator in enumerate(unique_estimators)}\n",
    "\n",
    "# Crear la nueva columna 'InternalOwnerId' utilizando el diccionario de mapeo\n",
    "df['EstimatorId'] = df['Estimator'].map(estimator_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c516557-a150-4730-b087-4e5f5e329082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'Trades'\n",
    "unique_trades = df['Trades'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "trade_to_id = {trade: i+1 for i, trade in enumerate(unique_trades)}\n",
    "\n",
    "# Crear la nueva columna 'TradeId' utilizando el diccionario de mapeo\n",
    "df['TradeId'] = df['Trades'].map(trade_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f939cf24-09b3-4bdc-9dfd-d6baa636c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'EndMarket'\n",
    "unique_endmarkets = df['EndMarket'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "endmarket_to_id = {endmarket: i+1 for i, endmarket in enumerate(unique_endmarkets)}\n",
    "\n",
    "# Crear la nueva columna 'EndMarketId' utilizando el diccionario de mapeo\n",
    "df['EndMarketId'] = df['EndMarket'].map(endmarket_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "288bf656-4d61-4b3f-acb0-f4688f3d9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ProjectStageId'] = np.where(df['ProjectStage'] == 'Bidding', 1, \n",
    "                                 np.where(df['ProjectStage'] == 'Awarded', 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c03cd569-c18e-49fa-be05-d29ffd8fe547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'ContactId'\n",
    "unique_contacts = df['ContactId'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "contact_to_id = {contact: i+1 for i, contact in enumerate(unique_contacts)}\n",
    "\n",
    "# Crear la nueva columna 'ContactId_int' utilizando el diccionario de mapeo\n",
    "df['ContactId_int'] = df['ContactId'].map(contact_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f934cffd-64a1-4482-8090-ed21a0443c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'AccountId'\n",
    "unique_accounts = df['AccountId'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "account_to_id = {account: i+1 for i, account in enumerate(unique_accounts)}\n",
    "\n",
    "# Crear la nueva columna 'AccountId_int' utilizando el diccionario de mapeo\n",
    "df['AccountId_int'] = df['AccountId'].map(account_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9616918-ded1-42f5-b900-fc57324df775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'AccountType'\n",
    "unique_acctypes = df['AccountType'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "acctype_to_id = {acctype: i+1 for i, acctype in enumerate(unique_acctypes)}\n",
    "\n",
    "# Crear la nueva columna 'AccountTypeId' utilizando el diccionario de mapeo\n",
    "df['AccountTypeId'] = df['AccountType'].map(acctype_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a56df39-ebfd-4cf2-b227-c00eb7e41af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'CustomerClass'\n",
    "unique_custclass = df['CustomerClass'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "custclass_to_id = {custclass: i+1 for i, custclass in enumerate(unique_custclass)}\n",
    "\n",
    "# Crear la nueva columna 'CustomerClassId' utilizando el diccionario de mapeo\n",
    "df['CustomerClassId'] = df['CustomerClass'].map(custclass_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68dd5004-632a-45fe-b901-4955e9ee6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'AccountIndustry'\n",
    "unique_accindustry = df['AccountIndustry'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "accindustry_to_id = {accindustry: i+1 for i, accindustry in enumerate(unique_accindustry)}\n",
    "\n",
    "# Crear la nueva columna 'AccountIndustryId' utilizando el diccionario de mapeo\n",
    "df['AccountIndustryId'] = df['AccountIndustry'].map(accindustry_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4bd5f6d-32a0-4641-9cc0-8099dfecaef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'CompanyType'\n",
    "unique_companytype = df['CompanyType'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "companytype_to_id = {companytype: i+1 for i, companytype in enumerate(unique_companytype)}\n",
    "\n",
    "# Crear la nueva columna 'CompanyTypeId' utilizando el diccionario de mapeo\n",
    "df['CompanyTypeId'] = df['CompanyType'].map(companytype_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8514b722-54ec-49cd-9faa-a73d9d1899ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener una lista de nombres únicos en la columna 'ProjectState'\n",
    "unique_projstate = df['ProjectState'].unique()\n",
    "\n",
    "# Crear un diccionario que mapee cada nombre único a un identificador único\n",
    "projstate_to_id = {projstate: i+1 for i, projstate in enumerate(unique_projstate)}\n",
    "\n",
    "# Crear la nueva columna 'CustomerClassId' utilizando el diccionario de mapeo\n",
    "df['ProjectStateId'] = df['ProjectState'].map(projstate_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "623e4dd5-a50d-4417-8913-fea0c8c8eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IsWonId'] = 0  # Inicialmente, establecemos todos los valores en 0\n",
    "df.loc[df['IsWon'] == True, 'IsWonId'] = 1  # Si IsWon es True, asignamos 1 a IsWonId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38c79efb-bf53-44e5-8c2e-a19d9c80abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ProjectId', 'Project', 'OppId','Opportunity', 'ProjectState', 'ProjectStateId', 'Division',\n",
    "         'DivisionId', 'DealType', 'DealTypeId','CreatedDate', 'CreatedDate2', 'DeliveryDate', 'CloseDate',\n",
    "         'InternalOwner', 'InternalOwnerId', 'SalesDivision', 'SalesDivisionId',\n",
    "         'Estimator', 'EstimatorId', 'Trades', 'TradeId', 'EndMarket', 'EndMarketId',\n",
    "         'ProjectStage', 'ProjectStageId', 'StageName', 'IsWon', 'IsWonId',\n",
    "         'Amount', 'AccountId', 'AccountName', 'AccountId_int', 'AccountType',\n",
    "         'AccountTypeId', 'CustomerClass', 'CustomerClassId', 'AccountIndustry', 'AccountIndustryId',\n",
    "         'CompanyType', 'CompanyTypeId', 'ContactId', 'Name', 'ContactId_int', 'Title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6f18afc-b865-4f94-852c-e4a452fd93d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "\n",
    "timezone = pytz.timezone('America/Los_Angeles')\n",
    "df1['CreatedDate'] = pd.to_datetime(df1['CreatedDate'])\n",
    "date_df_predictions = (datetime.now() - relativedelta(months=6)).astimezone(timezone)\n",
    "df1 = df1.loc[(df1['CreatedDate'] < date_df_predictions) | (df1['IsWon'] == True)]\n",
    "\n",
    "df1.drop(columns=['ProjectId', 'OppId', 'Division', 'DeliveryDate', 'CloseDate',\n",
    "                  'EndMarket', 'StageName', 'AccountIndustry', 'CompanyType', 'Title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b03eeec-6d20-4996-8ac2-9c43f223ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Project', 'Opportunity', 'ProjectState', 'ProjectStateId',\n",
      "       'DivisionId', 'DealType', 'DealTypeId', 'CreatedDate', 'CreatedDate2',\n",
      "       'InternalOwner', 'InternalOwnerId', 'SalesDivision', 'SalesDivisionId',\n",
      "       'Estimator', 'EstimatorId', 'Trades', 'TradeId', 'EndMarketId',\n",
      "       'ProjectStage', 'ProjectStageId', 'IsWon', 'IsWonId', 'Amount',\n",
      "       'AccountId', 'AccountName', 'AccountId_int', 'AccountType',\n",
      "       'AccountTypeId', 'CustomerClass', 'CustomerClassId',\n",
      "       'AccountIndustryId', 'CompanyTypeId', 'ContactId', 'Name',\n",
      "       'ContactId_int'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c59b2f38-3c15-467e-a76f-2347e6eeef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[LightGBM] [Info] Number of positive: 2614, number of negative: 3588\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 6202, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421477 -> initscore=-0.316713\n",
      "[LightGBM] [Info] Start training from score -0.316713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'colsample_bytree': 0.6733618039413735, 'learning_rate': 0.07084844859190755, 'max_depth': 8, 'min_split_gain': 0.002119891565915222, 'n_estimators': 138, 'num_leaves': 36, 'reg_alpha': 0.2623873301291946, 'reg_lambda': 0.19993048585762774, 'subsample': 0.6186662652854461}\n",
      "Best AUC-ROC Score:  0.9690129103253657\n",
      "Optimized LightGBM - Accuracy: 90.65%\n",
      "Optimized LightGBM - Precision: 0.89\n",
      "Optimized LightGBM - Recall: 0.89\n",
      "Optimized LightGBM - AUC-ROC: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las características y la variable objetivo\n",
    "X = df1[['ProjectStateId', 'DealTypeId', 'InternalOwnerId',\n",
    "         'SalesDivisionId', 'EstimatorId', 'TradeId',\n",
    "         'ProjectStageId', 'ContactId_int', 'AccountId_int',\n",
    "         'AccountTypeId', 'CustomerClassId', 'EndMarketId',\n",
    "         'CompanyTypeId', 'DivisionId', 'AccountIndustryId']]\n",
    "y = df1['IsWonId']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir los parámetros que queremos probar\n",
    "param_dist = {\n",
    "    'num_leaves': randint(20, 50),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'subsample': uniform(0.6, 0.4),\n",
    "    'colsample_bytree': uniform(0.6, 0.4),\n",
    "    'min_split_gain': uniform(0, 0.3),\n",
    "    'reg_alpha': uniform(0, 0.5),\n",
    "    'reg_lambda': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "# Inicializar el modelo\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Configurar la búsqueda aleatoria\n",
    "random_search = RandomizedSearchCV(estimator=lgb_model, param_distributions=param_dist,\n",
    "                                   n_iter=50, scoring='roc_auc', n_jobs=-1, cv=5, random_state=42, verbose=2)\n",
    "\n",
    "# Ejecutar la búsqueda aleatoria\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best AUC-ROC Score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluar el modelo con los mejores hiperparámetros en el conjunto de prueba\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "precision_best = precision_score(y_test, y_pred_best)\n",
    "recall_best = recall_score(y_test, y_pred_best)\n",
    "roc_auc_best = roc_auc_score(y_test, y_pred_proba_best)\n",
    "\n",
    "print(f'Optimized LightGBM - Accuracy: {accuracy_best * 100:.2f}%')\n",
    "print(f'Optimized LightGBM - Precision: {precision_best:.2f}')\n",
    "print(f'Optimized LightGBM - Recall: {recall_best:.2f}')\n",
    "print(f'Optimized LightGBM - AUC-ROC: {roc_auc_best:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29400ccd-d766-4735-8bdc-ba79e4146f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los valores únicos de las columnas 'InternalOwner', 'SalesDivision', etc.\n",
    "unique_states = df['ProjectState'].unique()\n",
    "unique_deals = df['DealType'].unique()\n",
    "unique_internal_owners = df['InternalOwner'].unique()\n",
    "unique_sales_divisions = df['SalesDivision'].unique()\n",
    "unique_estimators = df['Estimator'].unique()\n",
    "unique_trades = df['Trades'].unique()\n",
    "unique_projstages = df['ProjectStage'].unique()\n",
    "unique_contacts = df['Name'].unique()\n",
    "unique_accounts = df['AccountName'].unique()\n",
    "unique_acctypes = df['AccountType'].unique()\n",
    "unique_custclasses = df['CustomerClass'].unique()\n",
    "unique_endmarkets = df['EndMarket'].unique()\n",
    "unique_comptypes = df['CompanyType'].unique()\n",
    "unique_divisions = df['Division'].unique()\n",
    "unique_accindustries = df['AccountIndustry'].unique()\n",
    "\n",
    "# Crea un diccionario para mapear valores a IDs\n",
    "state_id_map = {state: state_id for state_id, state in enumerate(unique_states, start=1)}\n",
    "deal_id_map = {deal: deal_id for deal_id, deal in enumerate(unique_deals, start=1)}\n",
    "internal_owner_id_map = {owner: owner_id for owner_id, owner in enumerate(unique_internal_owners, start=1)}\n",
    "sales_division_id_map = {division: division_id for division_id, division in enumerate(unique_sales_divisions, start=1)}\n",
    "estimator_id_map = {estimator: estimator_id for estimator_id, estimator in enumerate(unique_estimators, start=1)}\n",
    "trade_id_map = {trade: trade_id for trade_id, trade in enumerate(unique_trades, start=1)}\n",
    "projstage_id_map = {projstage: projstage_id for projstage_id, projstage in enumerate(unique_projstages, start=1)}\n",
    "contact_id_map = {contact: contact_id for contact_id, contact in enumerate(unique_contacts, start=1)}\n",
    "account_id_map = {account: account_id for account_id, account in enumerate(unique_accounts, start=1)}\n",
    "acctype_id_map = {acctype: acctype_id for acctype_id, acctype in enumerate(unique_acctypes, start=1)}\n",
    "custclass_id_map = {custclass: custclass_id for custclass_id, custclass in enumerate(unique_custclasses, start=1)}\n",
    "endmarket_id_map = {endmarket: endmarket_id for endmarket_id, endmarket in enumerate(unique_endmarkets, start=1)}\n",
    "comptype_id_map = {comptype: comptype_id for comptype_id, comptype in enumerate(unique_comptypes, start=1)}\n",
    "division_id_map = {division: division_id for division_id, division in enumerate(unique_divisions, start=1)}\n",
    "accindustry_id_map = {accindustry: accindustry_id for accindustry_id, accindustry in enumerate(unique_accindustries, start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79285e36-7934-4df3-8533-d0af50909483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\test3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad32f083-4d76-42d2-9193-f7cc4ca7d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_test = '2024-06-01T00:00:00.000+0000'\n",
    "\n",
    "#query_test = f\"SELECT Id, Name, CreatedDate, Internal_Owner__c, IsWon, Conversion_Chances__c FROM Opportunity WHERE Project_stage__c != 'Operations' AND  CreatedDate >= {date_test}\"\n",
    "#response_test = sf.query(query_test)\n",
    "\n",
    "#records_test = response_test['records']\n",
    "#df_test = pd.DataFrame(records_test)\n",
    "\n",
    "#df_test.drop(columns=['attributes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8e39e06-8cb4-46d4-8bc9-4addc4e2c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.to_csv(r'C:\\Users\\AdrielPiacquadioENG\\Desktop\\Estimation\\Predicciones\\Forecasting Opps\\test4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb77c23e-67fa-41d5-9a01-9a1810c9ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opportunity_id = '006Uy0000095iCvIAI'\n",
    "#probability_value = 79.63\n",
    "\n",
    "#sf.Opportunity.update(opportunity_id, {'Conversion_Chances__c': probability_value})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd702e",
   "metadata": {},
   "source": [
    "### Predicting Closing Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a657622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import catboost as cb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c6a463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e26222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.sort_values(by='CreatedDate')\n",
    "df3 = df3.loc[df3['IsWon'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "863571de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['DeliveryDate'] = df3['DeliveryDate'].fillna(df3['CreatedDate2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f3117550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opportunity</th>\n",
       "      <th>CreatedDate</th>\n",
       "      <th>CreatedDate2</th>\n",
       "      <th>DeliveryDate</th>\n",
       "      <th>CloseDate</th>\n",
       "      <th>IsWon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>21-BKI-Alcon JCA 4S - As-built</td>\n",
       "      <td>2021-01-04 15:25:37+00:00</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>C0782-PPSC-21-Golden West College Language Arts</td>\n",
       "      <td>2021-01-04 16:21:01+00:00</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>20-TAC-UTRGV ION CO04</td>\n",
       "      <td>2021-01-04 18:44:00+00:00</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Northside Gwinnett ED Expansion CO01</td>\n",
       "      <td>2021-01-04 21:18:24+00:00</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>20-LOT-Dell Childrens Hospital-CO04</td>\n",
       "      <td>2021-01-05 21:03:02+00:00</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Opportunity  \\\n",
       "721                   21-BKI-Alcon JCA 4S - As-built   \n",
       "723  C0782-PPSC-21-Golden West College Language Arts   \n",
       "726                            20-TAC-UTRGV ION CO04   \n",
       "729             Northside Gwinnett ED Expansion CO01   \n",
       "743              20-LOT-Dell Childrens Hospital-CO04   \n",
       "\n",
       "                  CreatedDate CreatedDate2 DeliveryDate   CloseDate  IsWon  \n",
       "721 2021-01-04 15:25:37+00:00   2021-01-04   2021-01-04  2021-01-12   True  \n",
       "723 2021-01-04 16:21:01+00:00   2021-01-04   2021-01-04  2021-03-31   True  \n",
       "726 2021-01-04 18:44:00+00:00   2021-01-04   2021-01-04  2020-12-30   True  \n",
       "729 2021-01-04 21:18:24+00:00   2021-01-04   2021-01-04  2021-01-04   True  \n",
       "743 2021-01-05 21:03:02+00:00   2021-01-05   2021-01-05  2021-04-20   True  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[['Opportunity', 'CreatedDate', 'CreatedDate2', 'DeliveryDate', 'CloseDate', 'IsWon']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "953a36e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3264"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a63df554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['CreatedDate2'] = pd.to_datetime(df3['CreatedDate2'], format='%Y-%m-%d')\n",
    "df3['DeliveryDate'] = pd.to_datetime(df3['DeliveryDate'], format='%Y-%m-%d')\n",
    "df3['CloseDate'] = pd.to_datetime(df3['CloseDate'], errors='coerce')  # Asume formato ISO por defecto, ajusta si es necesario\n",
    "\n",
    "df3['DeliveryDate'] = df3['DeliveryDate'].fillna(df3['CreatedDate2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ce160f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['ClosingTime'] = np.where(df3['CloseDate'].notnull(), \n",
    "                                (df3['CloseDate'] - df3['CreatedDate2']).dt.days, \n",
    "                                 np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54c50880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['ClosingTime'] = np.where(df3['ClosingTime'] < 0, 0, df3['ClosingTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c15944aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.sort_values(by='ClosingTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f7a3484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo CatBoost con hiperparámetros optimizados:\n",
      "Mean Absolute Error (MAE): 15.89\n",
      "Mean Squared Error (MSE): 2066.77\n",
      "Root Mean Squared Error (RMSE): 45.46\n",
      "Coefficient of Determination (R²): 0.14\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las características y la variable objetivo\n",
    "\n",
    "X_df3 = df3[['ProjectStateId', 'DivisionId', 'DealTypeId', 'InternalOwnerId',\n",
    "         'SalesDivisionId', 'EstimatorId', 'TradeId', 'EndMarketId',\n",
    "         'ProjectStageId', 'ContactId_int', 'AccountId_int',\n",
    "         'AccountTypeId', 'CustomerClassId', 'AccountIndustryId',\n",
    "         'CompanyTypeId']]\n",
    "y_df3 = df3['ClosingTime']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_df3, X_test_df3, y_train_df3, y_test_df3 = train_test_split(X_df3, y_df3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir el modelo CatBoost\n",
    "cat_model_df3 = CatBoostRegressor(loss_function='MAE', logging_level='Silent')\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros\n",
    "param_grid_df3 = {\n",
    "    'iterations': np.arange(100, 1001, 100),\n",
    "    'depth': np.arange(2, 11, 2),\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 20),\n",
    "    'l2_leaf_reg': np.logspace(-3, 1, 5),\n",
    "    'border_count': np.arange(32, 129, 32)\n",
    "}\n",
    "\n",
    "# Búsqueda aleatoria de hiperparámetros\n",
    "random_search_df3 = RandomizedSearchCV(\n",
    "    estimator=cat_model_df3,\n",
    "    param_distributions=param_grid_df3,\n",
    "    n_iter=200,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ajustar el modelo con los mejores hiperparámetros\n",
    "random_search_df3.fit(X_train_df3, y_train_df3)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params_df3 = random_search_df3.best_params_\n",
    "\n",
    "# Ajustar el modelo con los mejores hiperparámetros\n",
    "cat_model_tuned_df3 = CatBoostRegressor(loss_function='MAE', **best_params_df3, logging_level='Silent')\n",
    "cat_model_tuned_df3.fit(X_train_df3, y_train_df3)\n",
    "\n",
    "# Hacer predicciones con el modelo ajustado\n",
    "y_pred_tuned_df3 = cat_model_tuned_df3.predict(X_test_df3)\n",
    "\n",
    "# Evaluar el rendimiento del modelo ajustado\n",
    "mae_tuned_df3 = mean_absolute_error(y_test_df3, y_pred_tuned_df3)\n",
    "mse_tuned_df3 = mean_squared_error(y_test_df3, y_pred_tuned_df3)\n",
    "rmse_tuned_df3 = np.sqrt(mse_tuned_df3)\n",
    "r2_tuned_df3 = r2_score(y_test_df3, y_pred_tuned_df3)\n",
    "\n",
    "# Imprimir las métricas del modelo ajustado\n",
    "print(f'Modelo CatBoost con hiperparámetros optimizados:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_tuned_df3:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_tuned_df3:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_tuned_df3:.2f}')\n",
    "print(f'Coefficient of Determination (R²): {r2_tuned_df3:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "daaed7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_actual = datetime.now()\n",
    "fecha_antesdeayer = fecha_actual - timedelta(days=2)\n",
    "fecha_antesdeayer_str = fecha_antesdeayer.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "05c63091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-23\n"
     ]
    }
   ],
   "source": [
    "print(fecha_antesdeayer_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41849221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener el ID mapeado\n",
    "def get_mapped_id(value, id_map):\n",
    "    return id_map.get(value)\n",
    "\n",
    "def predecir_iswon(project_state, deal_type, internal_owner,\n",
    "                   sales_division, estimator, trade,\n",
    "                   project_stage, contact_id, account_id,\n",
    "                   account_type, customer_class, end_market,\n",
    "                   company_type, division, account_industry):\n",
    "    # Mapear valores a IDs\n",
    "    state_id = get_mapped_id(project_state, state_id_map)\n",
    "    deal_id = get_mapped_id(deal_type, deal_id_map)\n",
    "    internal_owner_id = get_mapped_id(internal_owner, internal_owner_id_map)\n",
    "    sales_division_id = get_mapped_id(sales_division, sales_division_id_map)\n",
    "    estimator_id = get_mapped_id(estimator, estimator_id_map)\n",
    "    trade_id = get_mapped_id(trade, trade_id_map)\n",
    "    projstage_id = get_mapped_id(project_stage, projstage_id_map)\n",
    "    contact_id = get_mapped_id(contact_id, contact_id_map)\n",
    "    account_id = get_mapped_id(account_id, account_id_map)\n",
    "    acctype_id = get_mapped_id(account_type, acctype_id_map)\n",
    "    custclass_id = get_mapped_id(customer_class, custclass_id_map)\n",
    "    endmarket_id = get_mapped_id(end_market, endmarket_id_map)\n",
    "    comptype_id = get_mapped_id(company_type, comptype_id_map)\n",
    "    division_id = get_mapped_id(division, division_id_map)\n",
    "    accindustry_id = get_mapped_id(account_industry, accindustry_id_map)\n",
    "    # Haz lo mismo para las otras columnas\n",
    "\n",
    "    # Crear un DataFrame con los datos de entrada\n",
    "    data = pd.DataFrame({\n",
    "        'ProjectStateId': [state_id],\n",
    "        'DealTypeId': [deal_id],\n",
    "        'InternalOwnerId': [internal_owner_id],\n",
    "        'SalesDivisionId': [sales_division_id],\n",
    "        'EstimatorId': [estimator_id],\n",
    "        'TradeId': [trade_id],\n",
    "        'ProjectStageId': [projstage_id],\n",
    "        'ContactId_int': [contact_id],\n",
    "        'AccountId_int': [account_id],\n",
    "        'AccountTypeId': [acctype_id],\n",
    "        'CustomerClassId': [custclass_id],\n",
    "        'EndMarketId': [endmarket_id],\n",
    "        'CompanyTypeId': [comptype_id],\n",
    "        'DivisionId': [division_id],\n",
    "        'AccountIndustryId': [accindustry_id]\n",
    "    })\n",
    "\n",
    "    # Realizar la predicción con el modelo\n",
    "    prediction = best_model.predict(data)\n",
    "    \n",
    "    # Realizar la predicción de probabilidades con el modelo\n",
    "    predicted_proba = best_model.predict_proba(data)\n",
    "    \n",
    "    # Realizar la predicción de Closing Time\n",
    "    predicted_closing = cat_model_tuned_df3.predict(data)\n",
    "    predicted_closing_rounded = int(round(predicted_closing[0], 0))\n",
    "    predicted_closing_date = fecha_actual + timedelta(days=predicted_closing_rounded)\n",
    "    predicted_closing_date_str = predicted_closing_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Obtener la probabilidad de que la predicción sea igual a 1\n",
    "    prob_iswon = predicted_proba[:, best_model.classes_ == 1]\n",
    "    \n",
    "    # Devolver la predicción y la probabilidad resultante\n",
    "    return prediction[0], prob_iswon[0][0] * 100, predicted_closing_date_str # Predicción y probabilidad en porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7d137f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df.copy()\n",
    "df4 = df4.loc[(df4['CreatedDate'] >= fecha_antesdeayer_str)]\n",
    "\n",
    "if len(df4) > 0:\n",
    "    # Obtener las predicciones y probabilidades de conversión para cada proyecto en df4\n",
    "    def obtener_probabilidad(row):\n",
    "        close_date_str = row['CloseDate']\n",
    "        if row['IsWon']:\n",
    "            return 1, 100, close_date_str\n",
    "        else:\n",
    "            chances, probabilidad, closing = predecir_iswon(row['ProjectState'], row['DealType'],\n",
    "                                                   row['InternalOwner'], row['SalesDivision'],\n",
    "                                                   row['Estimator'], row['Trades'],\n",
    "                                                   row['ProjectStage'], row['Name'],\n",
    "                                                   row['AccountName'], row['AccountType'],\n",
    "                                                   row['CustomerClass'], row['EndMarket'],\n",
    "                                                   row['CompanyType'], row['Division'],\n",
    "                                                   row['AccountIndustry'])\n",
    "            return chances, probabilidad, closing\n",
    "\n",
    "    df4['WillBeWon?'], df4['ConversionChances'], df4['ExpectedClosing'] = zip(*df4.apply(obtener_probabilidad, axis=1))\n",
    "    \n",
    "else:\n",
    "    print(\"No projects found for today's date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5b6f43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df4.iterrows():\n",
    "    opportunity_id = row['OppId']\n",
    "    probability_value = row['ConversionChances']\n",
    "    expected_closing = row['ExpectedClosing']\n",
    "    \n",
    "    # Obtener los detalles actuales de la oportunidad\n",
    "    opportunity_details = sf.Opportunity.get(opportunity_id)\n",
    "    \n",
    "    # Verificar el valor del campo 'Are_you_using_a_package_strategy__c'\n",
    "    package_strategy = opportunity_details.get('Are_you_using_a_package_strategy__c', 'No')\n",
    "    \n",
    "    # Si el campo está vacío, asignar 'No'\n",
    "    if not package_strategy:\n",
    "        package_strategy = 'No'\n",
    "    \n",
    "    # Actualizar la oportunidad con los nuevos valores\n",
    "    sf.Opportunity.update(opportunity_id, {\n",
    "        'Conversion_Chances__c': probability_value,\n",
    "        'ExpectedClosing__c': expected_closing,\n",
    "        'Are_you_using_a_package_strategy__c': package_strategy\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073b8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
